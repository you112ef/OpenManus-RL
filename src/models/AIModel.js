const axios = require('axios');

class AIModel {
  constructor() {
    this.isOnline = true;
    this.localModel = null;
    this.modelStatus = 'initializing';
    this.conversationHistory = new Map();
    
    // Configuration
    this.config = {
      openai: {
        apiKey: process.env.OPENAI_API_KEY,
        model: 'gpt-3.5-turbo',
        baseURL: 'https://api.openai.com/v1'
      },
      local: {
        enabled: true,
        modelPath: './models/local-model',
        maxTokens: 2048
      }
    };

    // Arabic prompts and responses
    this.systemPrompts = {
      arabic: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø§Ø³Ù…Ù‡ "ÙŠÙˆØ³Ù Ø´Ø§Ù‡ÙŠÙ†" (YOUSEF SH). Ø£Ù†Øª Ù…ÙÙŠØ¯ ÙˆÙ…Ù‡Ø°Ø¨ ÙˆØªØ¬ÙŠØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙ‡ÙˆÙ…. 
      ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙˆØ§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª. ÙƒÙ† ÙˆØ¯ÙˆØ¯Ù‹Ø§ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ù‹Ø§ Ø¯Ø§Ø¦Ù…Ù‹Ø§.`,
      english: `You are an intelligent assistant named "YOUSEF SH". You are helpful, polite, and respond clearly. 
      You assist users with various topics and inquiries. Always be friendly and helpful.`
    };

    this.offlineResponses = [
      "Ø£Ø¹ØªØ°Ø±ØŒ Ø£Ø¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ù„ÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ",
      "Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ø¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‹Ø§ Ø¨Ø¯ÙˆÙ† Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†ØªØŒ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©.",
      "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø­Ø§Ù„ÙŠÙ‹Ø§. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠÙ‡ØŸ"
    ];
  }

  async initialize() {
    try {
      // Check internet connectivity
      await this.checkConnectivity();
      
      if (this.isOnline) {
        this.modelStatus = 'online';
        console.log('ğŸŒ AI Model running in online mode');
      } else {
        await this.initializeLocalModel();
        this.modelStatus = 'offline';
        console.log('ğŸ”Œ AI Model running in offline mode');
      }
    } catch (error) {
      console.error('Model initialization error:', error);
      this.modelStatus = 'error';
      this.isOnline = false;
    }
  }

  async checkConnectivity() {
    try {
      const response = await axios.get('https://api.openai.com/v1/models', {
        headers: {
          'Authorization': `Bearer ${this.config.openai.apiKey || 'test'}`
        },
        timeout: 5000
      });
      this.isOnline = true;
    } catch (error) {
      console.log('No internet connection or API unavailable, switching to offline mode');
      this.isOnline = false;
    }
  }

  async initializeLocalModel() {
    try {
      // Simulate local model initialization
      // In a real implementation, you would load a local model here
      // using libraries like transformers.js, tensorflow.js, or onnx
      
      this.localModel = {
        initialized: true,
        name: 'Local Arabic Model',
        version: '1.0.0'
      };
      
      console.log('ğŸ“¦ Local model initialized successfully');
    } catch (error) {
      console.error('Local model initialization failed:', error);
      throw error;
    }
  }

  async generateResponse(message, conversationId = 'default') {
    try {
      // Get or create conversation history
      if (!this.conversationHistory.has(conversationId)) {
        this.conversationHistory.set(conversationId, []);
      }
      
      const history = this.conversationHistory.get(conversationId);
      
      let response;
      
      if (this.isOnline && this.config.openai.apiKey) {
        response = await this.generateOnlineResponse(message, history);
      } else {
        response = await this.generateOfflineResponse(message, history);
      }

      // Update conversation history
      history.push(
        { role: 'user', content: message },
        { role: 'assistant', content: response }
      );

      // Keep only last 10 exchanges to manage memory
      if (history.length > 20) {
        history.splice(0, history.length - 20);
      }

      return response;
    } catch (error) {
      console.error('Response generation error:', error);
      return this.getErrorResponse();
    }
  }

  async generateOnlineResponse(message, history) {
    try {
      const messages = [
        { role: 'system', content: this.systemPrompts.arabic },
        ...history,
        { role: 'user', content: message }
      ];

      const response = await axios.post(
        `${this.config.openai.baseURL}/chat/completions`,
        {
          model: this.config.openai.model,
          messages: messages,
          max_tokens: 1000,
          temperature: 0.7,
          top_p: 0.9
        },
        {
          headers: {
            'Authorization': `Bearer ${this.config.openai.apiKey}`,
            'Content-Type': 'application/json'
          },
          timeout: 30000
        }
      );

      return response.data.choices[0].message.content;
    } catch (error) {
      console.error('Online response generation failed:', error);
      // Fallback to offline mode
      this.isOnline = false;
      return this.generateOfflineResponse(message, history);
    }
  }

  async generateOfflineResponse(message, history) {
    // Simple rule-based responses for offline mode
    const lowerMessage = message.toLowerCase();
    
    if (lowerMessage.includes('Ù…Ø±Ø­Ø¨Ø§') || lowerMessage.includes('Ø£Ù‡Ù„Ø§') || lowerMessage.includes('Ø§Ù„Ø³Ù„Ø§Ù…')) {
      return "Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ùƒ! Ø£Ù†Ø§ ÙŠÙˆØ³Ù Ø´Ø§Ù‡ÙŠÙ†ØŒ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ";
    }
    
    if (lowerMessage.includes('ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ') || lowerMessage.includes('Ø£Ø®Ø¨Ø§Ø±Ùƒ')) {
      return "Ø£Ø´ÙƒØ±Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„! Ø£Ø¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ ÙˆØ¬Ø§Ù‡Ø² Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù„ÙŠÙ‡ØŸ";
    }
    
    if (lowerMessage.includes('Ù…Ù† Ø£Ù†Øª') || lowerMessage.includes('Ø§Ø³Ù…Ùƒ')) {
      return "Ø£Ù†Ø§ ÙŠÙˆØ³Ù Ø´Ø§Ù‡ÙŠÙ† (YOUSEF SH)ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ø·ÙˆØ± Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª. Ø£Ø¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ù„ÙŠ.";
    }
    
    if (lowerMessage.includes('Ù…Ø³Ø§Ø¹Ø¯Ø©') || lowerMessage.includes('help')) {
      return "Ø¨Ø§Ù„Ø·Ø¨Ø¹! ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:\nâ€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©\nâ€¢ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\nâ€¢ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ù„Ø¯Ø±Ø¯Ø´Ø©\nâ€¢ Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©\n\nÙ…Ø§ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠÙ‡ØŸ";
    }
    
    if (lowerMessage.includes('ÙˆÙ‚Øª') || lowerMessage.includes('ØªØ§Ø±ÙŠØ®')) {
      const now = new Date();
      const arabicDate = now.toLocaleDateString('ar-EG', {
        weekday: 'long',
        year: 'numeric',
        month: 'long',
        day: 'numeric'
      });
      const arabicTime = now.toLocaleTimeString('ar-EG');
      return `Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø­Ø§Ù„ÙŠ: ${arabicDate}\nØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ: ${arabicTime}`;
    }
    
    // Default response with some variation
    const randomResponse = this.offlineResponses[
      Math.floor(Math.random() * this.offlineResponses.length)
    ];
    
    return `${randomResponse}\n\nØ³Ø¤Ø§Ù„Ùƒ: "${message}"\n\nØ¹Ø°Ø±Ù‹Ø§ØŒ Ø£Ø¹Ù…Ù„ Ø­Ø§Ù„ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆÙ‚Ø¯Ø±Ø§ØªÙŠ Ù…Ø­Ø¯ÙˆØ¯Ø©. Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø£Ùˆ Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ø¢Ø®Ø±ØŸ`;
  }

  getErrorResponse() {
    return "Ø£Ø¹ØªØ°Ø±ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ù‹Ø§.";
  }

  getModelStatus() {
    return {
      status: this.modelStatus,
      isOnline: this.isOnline,
      hasLocalModel: !!this.localModel,
      activeConversations: this.conversationHistory.size
    };
  }

  clearConversation(conversationId) {
    this.conversationHistory.delete(conversationId);
  }

  clearAllConversations() {
    this.conversationHistory.clear();
  }
}

module.exports = AIModel;